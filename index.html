<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="BADGR: Bundle Adjustment Diffusion Conditioned by GRadients for Wide-Baseline Floor Plan Reconstruction.">
  <meta name="keywords" content="BADGR, Bundle Adjustment, Diffusion, Leanred Optimization, Multi-view Reconstruction">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="icon" href="./static/images/floor-plan.png" type="image/svg+xml" />
  <title>BADGR: Bundle Adjustment Diffusion Conditioned by GRadients for Wide-Baseline Floor Plan Reconstruction</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link href="https://fonts.googleapis.com/css2?family=PT+Sans:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <!-- <script src="./static/js/bulma-carousel.min.js"></script> -->
  <script src="https://cdn.jsdelivr.net/npm/bulma-carousel/dist/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  
</head> 
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://yuguang-li.github.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136920610.pdf">
            CovisPose
          </a>
          <a class="navbar-item" href="https://github.com/zillow/salve">
            salve
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-3 publication-title">BADGR: Bundle Adjustment Diffusion Conditioned by GRadients for Wide-Baseline Floor Plan Reconstruction</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://yuguang-li.github.io">Yuguang Li</a><sup>&dagger;1</sup>,</span>
            <span class="author-block">
              <a href="https://iboyadzhiev.github.io/">Ivaylo Boyadzhiev</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=yjKOHbEAAAAJ&hl=zh-CN/">Zixuan Liu<sup>1</sup>,</a>
            </span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~shapiro/">Linda Shapiro</a><sup>*1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.colburn.org/">Alex Colburn</a><sup>*1</sup>,
            </span>
          </div> 

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <sup>1</sup>University of Washington <br>
              <sup>2</sup>Independent Researcher <br><br>
              The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2025
            </span>
            <span class="eql-cntrb"><small><br><sup>*</sup>Equal Contribution as Advisors</small></span>
            <span class="eql-cntrb"><small><br><sup>&dagger;</sup>Corresponding author â€” ylee3@cs.washington.edu</small></span>
            
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://cvpr.thecvf.com/virtual/2025/poster/33282"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2503.19340"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link.
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="**"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="**"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <div class="hero-body">
          <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/teaser.mp4"
                    type="video/mp4">
          </video> -->

          <!-- <p>
            <span class="hero-title w70">
              Input floor boundary estimates and global instance segmentation for walls derived from pairwise CovisPose model.
            </span>
          </p>
          <img src="./static/images/badgr_inputs_2.png" alt="Description of GIF" class="hero1"> -->

          <!-- <img src="./static/images/badgr_hero.mp4" alt="Description of GIF" loop=infinite> -->
          <video id="teaser" autoplay muted loop playsinline height="100%">
            <source src="./static/images/badgr_hero.mp4"
                    type="video/mp4">
          </video>
          <!-- <p>
            <span class="hero-title w70">
              BADGR:.
            </span>
          </p> -->
          
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-5">Objectives</h2>
        <div class="content has-text-justified">
          <p>
            <span class="bold-orange">BADGR</span> 
                  performs <span class="bold-blue">both bundle adjustment (BA) optimization and
                  layout inpainting</span> tasks, to refine camera poses and layouts from a given coarse state using 1D floor 
                  boundary information from up-to-30 or more images of varying input densities. The <span class="bold-blue">learned layout-structural constraints</span>, 
                  such as wall adjacency, collinearity, help BADGR to 1) constrain pose graph, 2) learn to mitigate errors from inputs, and 3) inpaint occluded layouts.
          </p> 
        </div>
        </div>
      </div>

      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <!-- <h2 class="title is-5">Background</h2>
          <div class="content has-text-justified">
            <p>
              Wide-baseline indoor reconstruction often suffers from a lack of robust matching features with sub-pixel accuracy.
            Direct 
            </p>
          </div> -->

          <h2 class="title is-5">Framework</h2>
          <div class="content has-text-justified">
            <p>
              <span class="bold-orange">BADGR</span> is <span class="bold-blue">a layout diffusion model conditioned on</span>
              dense per-column adjustment outputs from our proposed planar BA module, which is based on a single-step Levenberg Marquardt (LM) 
              optimizer. BADGR is trained to predict camera and wall positions while minimizing 
              both reprojection errors, where two iterative processes, i.e. non-linear optimization and performing layout generation, 
              are learned jointly with view-consistency and reconstrution losses. See <a href="#architecture">section below</a> for architecture details. 
            </p>
          </div>

          <h2 class="title is-5">Planar Bundle Adjustment</h2>
          <div class="content has-text-justified">
            <!-- <p>
              The objective of layout generation from denoising diffusion process complements 
              BA optimization by providing additional learned layout-structural constraints 
              on top of the co-visible features across images. These constraints help 
              <span class="bold-orange">BADGR</span> to make plausible guesses on spatial relations which help constrain pose 
              graph, such as wall adjacency, collinearity, and learn to mitigate errors from 
              dense boundary observations with global contexts.
            </p>
            <div class="img-container">
              <img src="./static/images/guided_all.gif" 
                   class="guided-diffusion-gif" 
                   alt="Guided diffusion."/>
              <figcaption>
                <span class="caption">
                  Although HouseDiffusion can be guided by our planar BA module, where 
                  the adjustments from single-step LM optimizer are added to diffusion outputs of each time step,
                  the two flows can conflict with each other, which results into jittering convergence. The 
                  output floor plan can violate the layout-structural constraints. The results won't converge from either diffusion or BA.
                </span> 
              </figcaption>
            </div> -->
            <p>
              Our <span class="bold-blue">planar bundle adjustment (BA)</span> minimizes reprojection errors between predicted floor boundaries 
              from image-based models and projected wall positions, adjusting wall translations along their normal direction and corresponding 
              camera poses. Before optimization, image columns from different images are grouped by global wall instances, with each wall 
              observed by multiple image columns and its floor boundary modeled as a line. Compared to point-based feature matching methods, 
              which often lack robust matching features with sub-pixel accuracy from wide-baseline indoor environments, our planar BA performs 
              feature matching at the global instance level for greater robustness and utilizes a larger portion of image columns during optimization. 
            </p>
            <div class="img-container w70">
              <video id="connection" autoplay muted loop playsinline height="100%">
                <source src="./static/images/ba_columns.mp4" type="video/mp4">
              </video>
            </div>
            <figcaption style="padding-bottom: 20px;">
              <span class="caption">Our planar BA module for adjusting both camera poses and walls using the predicted floor boundary as observations.</span> 
            </figcaption>

            <div class="img-container">
              <video id="connection" autoplay muted loop playsinline height="100%">
                <source src="./static/images/ba_only.mp4" type="video/mp4">
              </video>
              <!-- <img src="./static/images/ba_only.gif" alt="BADGR framework." /> -->
                <figcaption>
                  <span class="caption">
                    Planar BA optimization operates without learning components. Below, BADGR integrates this classic optimization into a denoising diffusion process, 
                    incorporating global layout constraints and inpainting objectives.
                  </span> 
                </figcaption>
            </div>
          </div>

          <h2 class="title is-5">Learned Global Constriants & <span class="bold-orange">BADGR</span></h2>
          <div class="content has-text-justified">
            <p>
              <span class="bold-blue">Layout-structural constraints</span>, such as wall adjacency and collinearity, are crucial 
              for accurate reconstruction, as sparse captures often limit visual overlap between images. Heuristic-based constraints 
              struggle to generalize and may not apply to all scenes. BADGR leverages a denoising diffusion model to learn these 
              constraints without complex regularization. It conditions on the planar BA mechanism, producing more accurate scene 
              refinements than planar BA alone. The diffusion model serves as posterior sampling at each BA step to improve accuracy 
              and efficiency.
            </p>
            <div class="img-container">
              <!-- <img src="./static/images/visual_connection.gif" 
                   alt="Visual connections."/> -->
              <div style="
                display: flex;
                align-items: center; margin: auto; justify-content: center;">
                <video id="connection" autoplay muted loop playsinline height="100%">
                  <source src="./static/images/visual_connection.mp4"
                          type="video/mp4">
                </video>
              </div>
              <figcaption>
                <span class="caption">
                  Planar BA along with learned layout-structural constaints 
                  effectively increases the amount of image columns usable for global optimization.
                </span> 
              </figcaption>
            </div>
            <!-- <p>
              The floor plan being optimized is represented angle-constrained with a Layout Directional Regularizer (LDR) to form a bidirectional 
              map between 2D room vertex positions and wall positions while maintaining fixed angles.
            </p> -->
          </div>
        </div> 
      </div>
      
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <div class="content has-text-justified">
            <p>
              <span class="bold-orange">BADGR</span> inherits the transformer-based layout 
              generation model from <a href="https://github.com/aminshabani/house_diffusion"><span class="bold-blue">HouseDiffusion</span></a>. Dense per-column planar BA guidance is 
              restructured and compressed into guidance embeddings, along with coordinate and 
              metadata embeddings for each wall and camera, which are then used as inputs to the 
              transformer engine. The model is trained to predict epsilon to x0. In other words, 
              BA guidance provides the gradients of adjustment, while the transformer makes the 
              final prediction on the refined layouts and poses, ensuring view consistency and 
              maintaining global constraints at each denoising step.

            </p>
            <div class="img-container" id="architecture">
              <img src="./static/images/architecture.gif" alt="BADGR framework." />
                <figcaption>
                  <span class="caption">
                    <span class="bold-orange">BADGR</span> architecture breakdown. Transformer is used to determine optimization adjustment given gradients.
                  </span> 
                </figcaption>
            </div>

            <p>
              Compared to a guided diffusion model like <a href="https://posediffusion.github.io/"><span class="bold-blue">PoseDiffusion</span></a>, 
              where guidance is simply added to the predicted adjustment, <span class="bold-orange">BADGR</span> learns to combine global layout-structural 
              constraints with the objective of maximizing view consistency, trained with an additional reprojection loss. 
              The model avoids conflicting flows, unlike guided diffusion, as shown below. Our quantitative results show that 
              BADGR is more accurate than both the guided diffusion model and the BA-only model, requiring 5X fewer iterations to 
              converge compared to the BA-only model.
            </p>

            <!-- <p>
              Unlike a guided diffusion model, such as <a href="https://posediffusion.github.io/">PoseDiffusion</a>, where the guidance 
              is simply added to the predicted adjustment, BADGR is conditioned 
              on dense per-column adjustments. The model learns to 
              combine global layout-structural constraints with the objective of maximizing view consistency.
              These constraints help 
              BADGR to make plausible guesses on spatial relations which help constrain pose 
              graph, such as wall adjacency, collinearity, and learn to mitigate errors from 
              dense boundary observations with global contexts. 
            </p> -->
            <div class="img-container">
              <img src="./static/images/guided_all.gif" 
                   class="guided-diffusion-gif" 
                   alt="Guided diffusion."/>
              <figcaption>
                <span class="caption">
                  In the example of HouseDiffusion guided by our planar BA module, adding the two flows causes jittery convergence, 
                  leading to violations of layout-structural constraints in the output floor plan. The optimization ends in sub-optimal 
                  states, with unresolved conflicts.
                </span> 
              </figcaption>
            </div>
            <p>
              <span class="dnerf">BADGR</span> trains exclusively on 2D floor plans with simulated floor boundaries generated on-the-fly during training, simplifying data acquisition, 
              enabling robust augmentation, and supporting variety of input densities. 
            </p>
          </div>
        </div>
      </div>
  </div>
</section>

<div class="columns is-centered has-text-centered">
  <div class="column is-full">
    <h2 class="title is-5">Examples & Accuracy on Zillow Indoor Datasets (ZInD)</h2>
  </div>
</div>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel1" class="carousel1 results-carousel1">
        <div class="item item-s1">
          <div style="
            width: 90%; display: flex;
            align-items: center; margin: auto; justify-content: center;">
            <img src="./static/quant_examples/quals_s1.png" id="s1" class="guided-diffusion-gif" 
            alt="Sample s1."/>
          </div>
        </div>
        <div class="item item-s2">
          <div style="
            width: 90%; display: flex;
            align-items: center; margin: auto; justify-content: center;">
            <img src="./static/quant_examples/quals_s2.png" id="s2" class="guided-diffusion-gif" 
            alt="Sample s2."/>
          </div>
        </div>
        <div class="item item-s3">
          <div style="
            width: 90%; display: flex;
            align-items: center; margin: auto; justify-content: center;">
            <img src="./static/quant_examples/quals_s3.png" id="s3" class="guided-diffusion-gif" 
            alt="Sample s3."/>
          </div>
        </div>
        <div class="item item-s4">
          <div style="
            width: 90%; display: flex;
            align-items: center; margin: auto; justify-content: center;">
            <img src="./static/quant_examples/quals_s4.png" id="s4" class="guided-diffusion-gif" 
            alt="Sample s4."/>
          </div>
        </div>
        <div class="item item-s5">
          <div style="
            width: 90%; display: flex;
            align-items: center; margin: auto; justify-content: center;">
            <img src="./static/quant_examples/quals_s5.png" id="s5" class="guided-diffusion-gif" 
            alt="Sample s5."/>
          </div>
        </div>
        <div class="item item-s6">
          <div style="
            width: 90%; display: flex;
            align-items: center; margin: auto; justify-content: center;">
            <img src="./static/quant_examples/quals_s6.png" id="s6" class="guided-diffusion-gif" 
            alt="Sample s6."/>
          </div>
        </div>
      </div>
    </div>
  </div>
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <div class="content has-text-justified">
          <p>
            Layout & camera poses. Left: Coarse outputs from 
            <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136920610.pdf"><span class="bold-blue">CovisPose</span></a>. 
            Mid: refined outputs from <span class="bold-orange">BADGR</span>. Right: Ground truth.
          </p> 
        </div>
        </div>
      </div>
    </div>
  </div>
  
</section>

<div class="columns is-centered has-text-centered" style="padding-top: 50px;">
  <div class="column is-full">
    <h2 class="title is-5" >More Optimization Examples on ZInD</h2>
  </div> 
</div>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-0039">
          <div style="
            width: 90%; display: flex;
            align-items: center; margin: auto; justify-content: center;">
            <video id="0039" autoplay muted loop playsinline height="100%">
              <source src="./static/samples/0039_f5d0e61ce2.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
        <div class="item item-0141">
          <div style="
            width: 95%; display: flex;
            align-items: center; margin: auto; justify-content: center;">
            <video id="0057" autoplay muted loop playsinline height="100%">
              <source src="./static/samples/0141_f16197ab2f_2.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
        <div class="item item-1326">
          <div style="
            width: 100%; display: flex;
            align-items: center; margin: auto; justify-content: center;">
            <video id="0021" autoplay muted loop playsinline height="100%">
              <source src="./static/samples/1326_bb0c79bec4.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
        <div class="item item-0336">
          <div style="
            width: 100%; display: flex;
            align-items: center; margin: auto; justify-content: center;">
            <video id="0021" autoplay muted loop playsinline height="100%">
              <source src="./static/samples/0336_acc8b13102_2.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
        <div class="item item-1218">
          <div style="
            width: 100%; display: flex;
            align-items: center; margin: auto; justify-content: center;">
            <video id="0021" autoplay muted loop playsinline height="100%">
              <source src="./static/samples/1218_951944515f.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
        <div class="item item-0021">
          <div style="
            width: 100%; display: flex;
            align-items: center; margin: auto; justify-content: center;">
            <video id="0021" autoplay muted loop playsinline height="100%">
              <source src="./static/samples/0021_e3e5a80990_2.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
        <div class="item item-0880">
          <div style="
            width: 100%; display: flex;
            align-items: center; margin: auto; justify-content: center;">
            <video id="0057" autoplay muted loop playsinline height="100%">
              <source src="./static/samples/0880_73700b826d.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
        <div class="item item-0406">
          <div style="
            width: 100%; display: flex;
            align-items: center; margin: auto; justify-content: center;">
            <video id="0021" autoplay muted loop playsinline height="100%">
              <source src="./static/samples/0406_5c9546f27c_2.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
        <div class="item item-0057">
          <div style="
            width: 95%; display: flex;
            align-items: center; margin: auto; justify-content: center;">
            <video id="0057" autoplay muted loop playsinline height="100%">
              <source src="./static/samples/0057_2bd44a63ca.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
        <div class="item item-1398">
          <div style="
            width: 95%; display: flex;
            align-items: center; margin: auto; justify-content: center;">
            <video id="0057" autoplay muted loop playsinline height="100%">
              <source src="./static/samples/1398_a930075ff7.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered"></div>

  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <div class="columns is-centered">
      <div class="column is-full">
        <h2 class="title is-5">BibTeX</h2>
        <pre><code>@article{li2025badgr
  author    = {Li, Yuguang and Boyadzhiev, Ivaylo and Liu, Zixuan and Shapiro, Linda and Colburn, Alex},
  title     = {BADGR: Bundle Adjustment Diffusion Conditioned by GRadients for Wide-Baseline Floor Plan Reconstruction},
  journal   = {CVPR},
  year      = {2025},
}</code> </pre> 
      </div>
    </div>
  </div>
</section>

<div class="container is-max-desktop">
  <!-- Abstract. -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-full">
      <h2 class="title is-5">Acknowledgements</h2>
      <div class="content has-text-justified">
        <p>
          We are grateful to <a href="https://www.singbingkang.com/">Sing Bing Kang</a> for discussions and paper edits on this work. 
          In addition, we appreciate Zillow Group on providing the FloorPlan-60K dataset throughout this research.
        </p>
      </div> 
    </div>
  </div>
</div>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="xx.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/yuguangli" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
